{
 "cells": [
  {
   "cell_type": "code",
   "id": "e66ddfc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T18:30:04.815486Z",
     "start_time": "2025-05-26T18:30:02.082557Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "from algorithms import *\n",
    "from snake_environment import *\n",
    "from states_bracket import *"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "c5a0433d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T18:30:06.181034Z",
     "start_time": "2025-05-26T18:30:06.168159Z"
    }
   },
   "source": [
    "def print_q_value(dictionary):\n",
    "    for d in dictionary:\n",
    "        print(f\"State ({d[0]}, {d[1]}), Action {d[2]} : Value {dictionary[d]}\")\n",
    "\n",
    "def opposite_action(action):\n",
    "    return {0:1, 1:0, 2:3, 3:2}[action]"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "09da74c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T18:30:07.513081Z",
     "start_time": "2025-05-26T18:30:07.496888Z"
    }
   },
   "source": [
    "# Bracketer\n",
    "bracketer = FoodRelativePositionBracket()\n",
    "# General Settings \n",
    "gamma = 0.9\n",
    "lr_v = 0.15\n",
    "epsilon = 0.4\n",
    "n_episodes = 5000"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "2710c15a",
   "metadata": {},
   "source": [
    "Proviamo il QLearning"
   ]
  },
  {
   "cell_type": "code",
   "id": "cacd472b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T18:20:38.243099Z",
     "start_time": "2025-05-26T18:14:52.892635Z"
    }
   },
   "source": [
    "# Environment\n",
    "env = SnakeEnv(render_mode=\"nonhuman\")\n",
    "Q_p = QLearning(env.action_space.n, gamma=gamma, lr_v=lr_v)\n",
    "Q_p.learning(env, epsilon, n_episodes, bracketer)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "752bc25e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T19:03:05.802528Z",
     "start_time": "2025-05-26T19:03:05.784023Z"
    }
   },
   "source": [
    "path = \"./models/\"\n",
    "Q_p.save(f\"{path}gamma {gamma} lr {lr_v} epsilon {epsilon} episodes {n_episodes}\")"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "id": "b2c332b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T19:03:03.466990Z",
     "start_time": "2025-05-26T19:03:03.393964Z"
    }
   },
   "source": [
    "env = SnakeEnv(render_mode=\"human\")\n",
    "path = \"./models/\"\n",
    "Q_p = QLearning(env.action_space.n, gamma=gamma, lr_v=lr_v)\n",
    "Q_p.upload(f\"{path}QLearning gamma {gamma} lr {lr_v} epsilon {epsilon} episodes {n_episodes}\")"
   ],
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './models/QLearning gamma 0.95 lr 0.001 epsilon 0.1 episodes 20001.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[36]\u001B[39m\u001B[32m, line 4\u001B[39m\n\u001B[32m      2\u001B[39m path = \u001B[33m\"\u001B[39m\u001B[33m./models/\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m      3\u001B[39m Q_p = QLearning(env.action_space.n, gamma=gamma, lr_v=lr_v)\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m \u001B[43mQ_p\u001B[49m\u001B[43m.\u001B[49m\u001B[43mupload\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43mf\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mpath\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[33;43mQLearning gamma \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mgamma\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[33;43m lr \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mlr_v\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[33;43m epsilon \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mepsilon\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[33;43m episodes \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mn_episodes\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\university\\reinforcement\\project\\algorithms.py:211\u001B[39m, in \u001B[36mRLAlgorithm.upload\u001B[39m\u001B[34m(self, path)\u001B[39m\n\u001B[32m    210\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mupload\u001B[39m(\u001B[38;5;28mself\u001B[39m, path):\n\u001B[32m--> \u001B[39m\u001B[32m211\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[33;43mf\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mpath\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[33;43m.pkl\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mrb\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[32m    212\u001B[39m         \u001B[38;5;28mself\u001B[39m.Qvalues = pickle.load(f)\n",
      "\u001B[31mFileNotFoundError\u001B[39m: [Errno 2] No such file or directory: './models/QLearning gamma 0.95 lr 0.001 epsilon 0.1 episodes 20001.pkl'"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "id": "d76db54d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T18:20:57.378580Z",
     "start_time": "2025-05-26T18:20:45.805661Z"
    }
   },
   "source": [
    "Q_p.play(env, bracketer)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "3f45dbe8",
   "metadata": {},
   "source": [
    "Proviamo SARSA"
   ]
  },
  {
   "cell_type": "code",
   "id": "2e6cf90f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T12:58:01.731940Z",
     "start_time": "2025-05-26T12:58:01.722112Z"
    }
   },
   "source": [
    "# Environment\n",
    "env = SnakeEnv(render_mode=\"nonhuman\")\n",
    "\n",
    "SARSA_p = SARSA(env.action_space.n, gamma=gamma, lr_v=lr_v)\n",
    "#SARSA_p.learning(env, epsilon, n_episodes, bracketer)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d84dfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./models/\"\n",
    "#SARSA_p.save(f\"{path}SARSA gamma {gamma} lr {lr_v} epsilon {epsilon} episodes {n_episodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "f1cd804f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T12:58:03.107513Z",
     "start_time": "2025-05-26T12:58:03.094175Z"
    }
   },
   "source": [
    "SARSA_p.upload(f\"{path}SARSA gamma {gamma} lr {lr_v} epsilon {epsilon} episodes {n_episodes}\")"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "049625d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T12:58:41.397611Z",
     "start_time": "2025-05-26T12:58:35.963502Z"
    }
   },
   "source": [
    "done = False\n",
    "keep = True\n",
    "env = SnakeEnv(render_mode=\"human\")\n",
    "state, _ = env.reset()\n",
    "state = bracketer.bracket(state)\n",
    "possible_action = [0, 1, 2, 3]\n",
    "last_action = None\n",
    "\n",
    "while not done and keep:\n",
    "    if last_action != None:\n",
    "        possible_action = [0, 1, 2, 3]\n",
    "        possible_action.remove(opposite_action(last_action))\n",
    "    action = SARSA_p.get_action_greedy(state, possible_action=possible_action)\n",
    "    last_action = action\n",
    "    state, reward, done, trunc, inf = env.step(action)\n",
    "    state = bracketer.bracket(state)\n",
    "    keep = env.render()\n",
    "\n",
    "env.close()"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "81949c38",
   "metadata": {},
   "source": "Setting gamma to 0.999 (so having a time horizon of 1000 and a maximum number of steps of 1000) make the agent learn something about how to approach food in order to prevent to end in its own tail."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Proviamo DDQN\n",
   "id": "976983c21574e86e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T18:30:18.551942Z",
     "start_time": "2025-05-26T18:30:16.309479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "BATCH_SIZE = 128\n",
    "MEMORY_SIZE = 10000\n",
    "TARGET_UPDATE_FREQ = 200\n",
    "\n",
    "# Bracketer\n",
    "bracketer = FoodRelativePositionBracket()\n",
    "# General Settings\n",
    "gamma = 0.95\n",
    "lr_v = 0.001\n",
    "epsilon = 0.1\n",
    "n_episodes = 20001\n",
    "\n",
    "# Environment\n",
    "env = SnakeEnv(render_mode=\"nonhuman\")\n",
    "state_dim = bracketer.get_state_dim()\n",
    "\n",
    "ddqn = DeepDoubleQLearning(\n",
    "    env.action_space.n,\n",
    "    state_dim=state_dim,\n",
    "    gamma=gamma,\n",
    "    lr_v=lr_v,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    memory_size=MEMORY_SIZE,\n",
    "    target_update_freq=TARGET_UPDATE_FREQ,\n",
    "    device='cpu'\n",
    ")"
   ],
   "id": "3edd2cfc86fab5f6",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T18:58:09.556282Z",
     "start_time": "2025-05-26T18:30:20.586021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "env = SnakeEnv(render_mode=\"nonhuman\")\n",
    "ddqn.learning(env, epsilon, n_episodes, bracketer)"
   ],
   "id": "3019b70901ba8f18",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "11500\n",
      "12000\n",
      "12500\n",
      "13000\n",
      "13500\n",
      "14000\n",
      "14500\n",
      "15000\n",
      "15500\n",
      "16000\n",
      "16500\n",
      "17000\n",
      "17500\n",
      "18000\n",
      "18500\n",
      "19000\n",
      "19500\n",
      "20000\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T18:59:44.250815Z",
     "start_time": "2025-05-26T18:59:44.234853Z"
    }
   },
   "cell_type": "code",
   "source": [
    "current_path = os.getcwd()\n",
    "model_path = os.path.join(current_path, \"models/\")\n",
    "print(f\"Model path: {model_path}\")"
   ],
   "id": "4a77dd8a245e9973",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model path: D:\\university\\reinforcement\\project\\models/\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T18:59:46.690195Z",
     "start_time": "2025-05-26T18:59:46.674965Z"
    }
   },
   "cell_type": "code",
   "source": "ddqn.save(f\"{model_path}DDQN gamma {gamma} lr {lr_v} epsilon {epsilon} episodes {n_episodes}\")",
   "id": "276094db05c61d64",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T19:00:20.195364Z",
     "start_time": "2025-05-26T19:00:20.180526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "env = SnakeEnv(render_mode=\"human\")\n",
    "state_dim = bracketer.get_state_dim()\n",
    "ddqn = DeepDoubleQLearning(\n",
    "    env.action_space.n,\n",
    "    state_dim=state_dim,\n",
    "    gamma=gamma,\n",
    "    lr_v=lr_v,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    memory_size=MEMORY_SIZE,\n",
    "    target_update_freq=TARGET_UPDATE_FREQ\n",
    ")\n",
    "ddqn.upload(f\"{model_path}DDQN gamma {gamma} lr {lr_v} epsilon {epsilon} episodes {n_episodes}\")"
   ],
   "id": "74eeb13a6dc86102",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T19:01:48.091326Z",
     "start_time": "2025-05-26T19:01:44.856188Z"
    }
   },
   "cell_type": "code",
   "source": "ddqn.play(env, bracketer)",
   "id": "d349154f4083194e",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T19:01:23.454783Z",
     "start_time": "2025-05-26T19:01:23.446791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Q values:\")\n",
    "for state, action in ddqn.Qvalues.items():\n",
    "    print(f\"State: {state}, Action: {action}, Value: {ddqn.q_values[(state, action)]}\")\n"
   ],
   "id": "1d2909a15c06500d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q values:\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Monte Carlo",
   "id": "47e533fece0d0206"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T18:23:15.188125Z",
     "start_time": "2025-05-26T18:23:15.180820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "env = SnakeEnv(render_mode=\"nonhuman\")\n",
    "\n",
    "MC = Montecarlo(env.action_space.n, gamma=gamma, lr_v=lr_v)"
   ],
   "id": "bf56d6412785bd98",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T18:25:02.466553Z",
     "start_time": "2025-05-26T18:23:16.596970Z"
    }
   },
   "cell_type": "code",
   "source": "MC.learning(env, epsilon, n_episodes, bracketer)",
   "id": "96d0b0134fcda960",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T19:02:22.054416Z",
     "start_time": "2025-05-26T19:02:22.046051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path = \"./models/\"\n",
    "MC.save(f\"{path}MC gamma {gamma} lr {lr_v} epsilon {epsilon} episodes {n_episodes}\")"
   ],
   "id": "22decd2ce0d07523",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T19:02:48.247358Z",
     "start_time": "2025-05-26T19:02:48.228947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "env = SnakeEnv(render_mode=\"human\")\n",
    "MC = Montecarlo(env.action_space.n, gamma=gamma, lr_v=lr_v)\n",
    "MC.upload(f\"{path}MC gamma {gamma} lr {lr_v} epsilon {epsilon} episodes {n_episodes}\")"
   ],
   "id": "8219ca85cdcdcfb",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T19:02:55.130061Z",
     "start_time": "2025-05-26T19:02:53.345676Z"
    }
   },
   "cell_type": "code",
   "source": "MC.play(env, bracketer)",
   "id": "6c8883e75e237442",
   "outputs": [],
   "execution_count": 35
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
