{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Jupyter Snake",
   "id": "a05b103b4ff69551"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## General Imports",
   "id": "372722fb230b07a6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T06:02:08.531947Z",
     "start_time": "2025-06-19T06:01:47.417148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "from algorithms import *\n",
    "from snake_environment import *\n",
    "from states_bracket import *\n",
    "from epsilon_scheduler import *\n",
    "from states_bracket import NeighPlusFoodDirectionPlusTailBracket\n",
    "from utils import *"
   ],
   "id": "3fbb87f4d67bc3c0",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T06:02:08.548951Z",
     "start_time": "2025-06-19T06:02:08.543709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "current_path = os.getcwd()\n",
    "models_path = current_path + \"/models/\""
   ],
   "id": "a10907104cb44a5d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Bracketer\n",
    "bracketer = NeighPlusFoodDirectionBracket(neigh=\"V\", radius=1)\n",
    "# General Settings\n",
    "gamma = 0.99\n",
    "lr_v = 0.15\n",
    "n_episodes = 25000\n",
    "epsilon_schedule = LinearEpsilonDecay(eps=1, coefficient=0.999, minimum=0.15)"
   ],
   "id": "8960fbdf61e50e5d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## QLearning",
   "id": "5d82ae111581299b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Environment\n",
    "env = SnakeEnv(render_mode=\"nonhuman\", max_step=1000)\n",
    "Q_p = QLearning(env.action_space.n, gamma=gamma, lr_v=lr_v)\n",
    "Q_p.learning(env, epsilon_schedule, n_episodes, bracketer)"
   ],
   "id": "f1e1fd92da37de40"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "name_specs = f'linear from 1 to 015 with 0999 as coefficient vn1 plus fd 1000 max iterations'\n",
    "model_path = f\"{models_path}QLearning gamma {gamma} lr {lr_v} epsilon {name_specs} 2nd\""
   ],
   "id": "a34247197f73784d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "Q_p.save(f\"{model_path}\")",
   "id": "cb0466c9504aa8ae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "Q_p.upload(f\"{model_path}\")",
   "id": "3d3fa0eb974c97ac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "env = SnakeEnv(render_mode=\"human\", max_step=1000)\n",
    "Q_p.play(env, bracketer)"
   ],
   "id": "4782579df15228c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "Q_p.print_q_values(bracketer)",
   "id": "972423a6523b4324"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##  SARSA",
   "id": "bab3f619fdbcea8c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Environment\n",
    "epsilon_schedule = LinearEpsilonDecay(eps=1, coefficient=0.9999, minimum=0.30)\n",
    "env = SnakeEnv(render_mode=\"nonhuman\", max_step=1000)\n",
    "SARSA_p = SARSA(env.action_space.n, gamma=gamma, lr_v=lr_v)\n",
    "bracketer = FoodDirectionBracket()\n",
    "SARSA_p.learning(env, epsilon_schedule, n_episodes=50000, bracketer=bracketer)"
   ],
   "id": "89db6ce4fbeed9d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "name_specs = f'linear from 1 to 030 with 09999 as coefficient vn1 plus fd 1000 max iterations'\n",
    "model_path = f\"{models_path}SARSA gamma {gamma} lr {lr_v} epsilon {name_specs}\""
   ],
   "id": "6788997c82a275d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "SARSA.save(f\"{model_path}\")",
   "id": "aa51d3c44bbfaef9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "SARSA.upload(f\"{model_path}\")",
   "id": "6fe87927cfbd97ae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "env = SnakeEnv(render_mode=\"human\", max_step=1000)\n",
    "SARSA_p.play(env, bracketer)"
   ],
   "id": "9d267144e6df23db"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "SARSA.print_q_values(bracketer)",
   "id": "89323b476d30fbe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Monte Carlo",
   "id": "d9bf72fd6fdd502c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Environment\n",
    "env = SnakeEnv(render_mode=\"nonhuman\")\n",
    "n_episodes = 5000\n",
    "bracketer = NeighPlusFoodDirectionBracket(neigh=\"V\", radius=1)\n",
    "MC = Montecarlo(env.action_space.n, gamma=gamma, lr_v=lr_v)"
   ],
   "id": "c77a02aa47778ebc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "MC.learning(env, epsilon_schedule, n_episodes, bracketer)",
   "id": "2c495621bf067b8c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model_path = f\"{models_path}MC gamma {gamma} lr {lr_v} epsilon {epsilon_schedule} episodes {n_episodes} bracketer {bracketer.__class__.__name__}\"",
   "id": "c7ff1db84a175c6a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "MC.save(f\"{model_path}\")",
   "id": "8799b28cf3ad44b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "MC.upload(f\"{model_path}\")",
   "id": "c8730f746d3f27f2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "env = SnakeEnv(render_mode=\"human\")\n",
    "MC.play(env, bracketer)"
   ],
   "id": "10ffbd3c572be354"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "get_model_average_performance(model_name='MC', action_space=env.action_space.n, gamma=gamma, lr_v=lr_v, model_path=model_path, bracketer=bracketer, num_episodes=1000, render_mode='nonhuman')",
   "id": "698da4aad452beca"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Double Deep Q-Learning",
   "id": "c5bf09418e252a7f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T06:32:04.887269Z",
     "start_time": "2025-06-19T06:32:04.879679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Environment\n",
    "batch_size = 128\n",
    "memory_size = 10000\n",
    "target_update_freq = 200\n",
    "\n",
    "# Bracketer\n",
    "bracketer = NeighPlusFoodRelativePositionPlusTailBracket(neigh='M', radius=5)\n",
    "\n",
    "# General Settings\n",
    "gamma = 0.95\n",
    "lr_v = 0.001\n",
    "epsilon = 0.1\n",
    "n_episodes = 5000\n",
    "epsilon_schedule = LinearEpsilonDecay(eps=1, coefficient=0.999, minimum=0.05)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = 'xpu' if torch.xpu.is_available() else device\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Environment\n",
    "env = SnakeEnv(render_mode=\"nonhuman\")\n",
    "state_dim = bracketer.get_state_dim()"
   ],
   "id": "fac0d1458d0f04ce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: xpu\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T06:32:06.148865Z",
     "start_time": "2025-06-19T06:32:06.120899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ddql = DeepDoubleQLearning(\n",
    "    env.action_space.n,\n",
    "    state_dim=state_dim,\n",
    "    gamma=gamma,\n",
    "    lr_v=lr_v,\n",
    "    batch_size=batch_size,\n",
    "    memory_size=memory_size,\n",
    "    target_update_freq=target_update_freq,\n",
    "    device=device\n",
    ")"
   ],
   "id": "66d5bc2945f0c4a4",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T17:25:42.682691Z",
     "start_time": "2025-06-18T17:25:39.146573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "env = SnakeEnv(render_mode='nonhuman', max_step=1000)\n",
    "ddql.learning(env, epsilon_schedule, n_episodes, bracketer)"
   ],
   "id": "11811170f4b7ea25",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m env = SnakeEnv(render_mode=\u001B[33m'\u001B[39m\u001B[33mnonhuman\u001B[39m\u001B[33m'\u001B[39m, max_step=\u001B[32m1000\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m \u001B[43mddql\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlearning\u001B[49m\u001B[43m(\u001B[49m\u001B[43menv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepsilon_schedule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_episodes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbracketer\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\university\\reinforcement\\project_rl\\algorithms.py:191\u001B[39m, in \u001B[36mRLAlgorithm.learning\u001B[39m\u001B[34m(self, env, epsilon_schedule, n_episodes, bracketer)\u001B[39m\n\u001B[32m    188\u001B[39m new_a = \u001B[38;5;28mself\u001B[39m.get_action_during_learning(new_s, possible_actions=possible_actions)\n\u001B[32m    190\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.single_step_update.\u001B[34m__func__\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m RLAlgorithm.single_step_update:   \u001B[38;5;66;03m#single_step_update was overridden\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m191\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msingle_step_update\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maction\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreward\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnew_s\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnew_a\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdone\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    193\u001B[39m action = new_a\n\u001B[32m    194\u001B[39m state = new_s\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\university\\reinforcement\\project_rl\\algorithms.py:596\u001B[39m, in \u001B[36mDeepDoubleQLearning.single_step_update\u001B[39m\u001B[34m(self, s, a, r, new_s, new_a, done)\u001B[39m\n\u001B[32m    594\u001B[39m \u001B[38;5;66;03m# Update the online DQN\u001B[39;00m\n\u001B[32m    595\u001B[39m \u001B[38;5;28mself\u001B[39m.optimizer.zero_grad()\n\u001B[32m--> \u001B[39m\u001B[32m596\u001B[39m \u001B[43mloss\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    597\u001B[39m \u001B[38;5;28mself\u001B[39m.optimizer.step()\n\u001B[32m    599\u001B[39m \u001B[38;5;66;03m# Update the target DQN every `self.target_update_freq` iterations\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\_tensor.py:648\u001B[39m, in \u001B[36mTensor.backward\u001B[39m\u001B[34m(self, gradient, retain_graph, create_graph, inputs)\u001B[39m\n\u001B[32m    638\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    639\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[32m    640\u001B[39m         Tensor.backward,\n\u001B[32m    641\u001B[39m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[32m   (...)\u001B[39m\u001B[32m    646\u001B[39m         inputs=inputs,\n\u001B[32m    647\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m648\u001B[39m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mautograd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    649\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs\u001B[49m\n\u001B[32m    650\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\autograd\\__init__.py:353\u001B[39m, in \u001B[36mbackward\u001B[39m\u001B[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[39m\n\u001B[32m    348\u001B[39m     retain_graph = create_graph\n\u001B[32m    350\u001B[39m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[32m    351\u001B[39m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[32m    352\u001B[39m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m353\u001B[39m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    354\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    355\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    356\u001B[39m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    357\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    358\u001B[39m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    359\u001B[39m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    360\u001B[39m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    361\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\autograd\\graph.py:824\u001B[39m, in \u001B[36m_engine_run_backward\u001B[39m\u001B[34m(t_outputs, *args, **kwargs)\u001B[39m\n\u001B[32m    822\u001B[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[32m    823\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m824\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_execution_engine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[32m    825\u001B[39m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    826\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[32m    827\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    828\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T06:32:08.411910Z",
     "start_time": "2025-06-19T06:32:08.406030Z"
    }
   },
   "cell_type": "code",
   "source": "model_path = f\"{models_path}DDQL gamma {gamma} lr {lr_v} epsilon {epsilon} episodes {n_episodes} bracketer {bracketer.__class__.__name__} Moore radius 5\"",
   "id": "bd58c976e987ecd5",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T06:30:10.984622Z",
     "start_time": "2025-06-19T06:30:10.963475Z"
    }
   },
   "cell_type": "code",
   "source": "ddql.save(path=f'{model_path}')",
   "id": "57683cde5067a28",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T06:32:10.146124Z",
     "start_time": "2025-06-19T06:32:10.131116Z"
    }
   },
   "cell_type": "code",
   "source": "ddql.upload(model_path)",
   "id": "c170c15a81411d1a",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T17:26:09.006046Z",
     "start_time": "2025-06-18T17:25:49.425235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "env = SnakeEnv(render_mode='human', max_step=5000)\n",
    "ddql.play(env, bracketer)"
   ],
   "id": "c2199955ecbeff21",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "get_model_average_performance(\n",
    "    model_name='DDQL',\n",
    "    action_space=env.action_space.n,\n",
    "    gamma=gamma,\n",
    "    lr_v=lr_v,\n",
    "    model_path=model_path,\n",
    "    bracketer=bracketer,\n",
    "    num_episodes=500,\n",
    "    render_mode='nonhuman',\n",
    "    state_dim=state_dim,\n",
    "    batch_size=batch_size,\n",
    "    memory_size=memory_size,\n",
    "    target_update_freq=target_update_freq,\n",
    "    device=device\n",
    ")"
   ],
   "id": "d88674f1d4ab4af8",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 500/500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(33.984,\n",
       " 15.596,\n",
       " array([114.,   4.,   5.,   6.,   6.,   2.,   3.,   7.,   4.,   7.,   6.,\n",
       "         11.,   8.,   7.,  14.,  12.,  14.,  23.,  13.,  15.,  16.,  13.,\n",
       "         20.,  22.,  24.,  23.,  13.,  19.,   9.,  14.,  14.,   8.,   2.,\n",
       "          8.,   5.,   3.,   3.,   1.,   1.,   1.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
